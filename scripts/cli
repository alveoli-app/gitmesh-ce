#!/usr/bin/env bash


set -eo pipefail

PROJECT_NAME="gitmesh"
DOCKER_NETWORK_SUBNET="${NETWORK_SUBNET:-10.90.0.0/24}"
DOCKER_NETWORK_GATEWAY="${NETWORK_GATEWAY:-10.90.0.1}"
DOCKET_TEST_NETWORK_SUBNET="${TEST_NETWORK_SUBNET:-10.91.0.0/24}"
DOCKER_TEST_NETWORK_GATEWAY="${TEST_NETWORK_GATEWAY:-10.91.0.1}"

CLI_HOME="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
source $CLI_HOME/utils

CONTAINERS=`ls -p $CLI_HOME/services | grep -v / | sed 's/\.[^.]*$//'`
BUILDERS=`ls -p $CLI_HOME/builders | grep -v / | sed 's/\.[^.]*$//'`

_DC="docker compose"

arch=$(uname -m)

if [ "$arch" == 'arm64' ];
then
  DOCKER_PLATFORM_FLAGS="--platform=linux/arm64/v8"
else
  DOCKER_PLATFORM_FLAGS="--platform=linux/amd64"
fi

function prepare_dev_env() {
    if [[ ! -f "$CLI_HOME/../backend/.env.override.local" ]]; then
        echo "# Here you can put environment variables that you would like to override when using local environment" > "$CLI_HOME/../backend/.env.override.local"
    fi
    if [[ ! -f "$CLI_HOME/../backend/.env.override.composed" ]]; then
        echo "# Here you can put environment variables that you would like to override when using local environment" > "$CLI_HOME/../backend/.env.override.composed"
    fi

    if [[ ! -f "$CLI_HOME/../frontend/.env.override.local" ]]; then
        echo "# Here you can put environment variables that you would like to override when using local environment" > "$CLI_HOME/../frontend/.env.override.local"
    fi

    if [[ ! -f "$CLI_HOME/../frontend/.env.override.composed" ]]; then
        echo "# Here you can put environment variables that you would like to override when using local environment" > "$CLI_HOME/../frontend/.env.override.composed"
    fi

    if [[ -d "$CLI_HOME/../chat-orchestrator" ]]; then
        if [[ ! -f "$CLI_HOME/../chat-orchestrator/.env.override.local" ]]; then
            echo "# Here you can put environment variables that you would like to override when using local environment" > "$CLI_HOME/../chat-orchestrator/.env.override.local"
        fi

        if [[ ! -f "$CLI_HOME/../chat-orchestrator/.env.override.composed" ]]; then
            echo "# Here you can put environment variables that you would like to override when using local environment" > "$CLI_HOME/../chat-orchestrator/.env.override.composed"
        fi
    fi

    set +eo pipefail

    $_DC >> /dev/null 2>&1

    if [[ ! $? -eq 0 ]]; then
        _DC="docker-compose"
        $_DC >> /dev/null 2>&1

        if [[ ! $? -eq 0 ]]; then
            error "Docker compose not detected!"
            exit 1
        fi
    fi

    set -eo pipefail
}

prepare_dev_env

function prepare_service_string() {
    if [ $1 == "HELP" ]; then delimiter1=" | "; delimiter2=" => | "; fi
    if [ $1 == "LIST" ]; then delimiter1="\|"; delimiter2="\|"; fi

    for cmd in $SERVICE_CMD; do string+="$cmd$delimiter1"; done
    for container in $2; do string+="$container$delimiter2"; done

    echo ${string%??}
}

HELP_STRING=$(prepare_service_string HELP "$CONTAINERS")
LIST_STRING=$(prepare_service_string LIST "$CONTAINERS")
HELP_BUILD_STRING=$(prepare_service_string HELP "$BUILDERS")

function build() {
    HELP="${RESET}\nUsage:\n ./cli build [ $HELP_BUILD_STRING ]\n"
    [[ -z "$1" ]] && say "$HELP" && exit 1

    if [[ $BUILDERS =~ (^|[[:space:]])"$1"($|[[:space:]]) ]] ; then
        build_and_publish "$@"
    else
        error "Invalid command '$1'" && say "$HELP"
        exit 1;
    fi
}

function create_migration() {
    MIG_NAME="$1"
    MIG_VERSION=$(date +%s)
    UP_MIG_FILE="${CLI_HOME}/../backend/src/database/migrations/V${MIG_VERSION}__${MIG_NAME}.sql"
    DOWN_MIG_FILE="${CLI_HOME}/../backend/src/database/migrations/U${MIG_VERSION}__${MIG_NAME}.sql"
    touch $UP_MIG_FILE
    touch $DOWN_MIG_FILE
    yell "Created ${MIG_FILE}";
}

function build_and_publish() {
    VERSION="$2"

    if [[ -z "${VERSION}" ]]; then
        COMMIT_HASH=`git rev-parse --short HEAD`
        TS_VERSION=$(date +%s)
        VERSION="$TS_VERSION.$COMMIT_HASH"
    fi

    source $CLI_HOME/builders/$1.sh

    say "Building $REPO version $VERSION with dockerfile '$DOCKERFILE' and context '$CONTEXT' and pushing it to $REPO:$VERSION"
    docker build --platform linux/amd64 --tag "$REPO:$VERSION" -f "$DOCKERFILE" "$CONTEXT"

    if [[ ${PUSH} ]]; then
        say "Pushing image $REPO version $VERSION to $REPO:$VERSION"
        docker push "$REPO:$VERSION"
    fi
}

function db_backup() {
    [[ -z "$1" ]] && error "Dump name has to be provided as first parameter!" && exit 1

    mkdir -p $CLI_HOME/db_dumps

    say "Cloning local database to $CLI_HOME/db_dumps/$1.dump!"
    docker exec -t ${PROJECT_NAME}_db_1 bash -c "PGPASSWORD=example pg_dump -F c -d gitmesh-web -U postgres > /$1.dump"
    docker cp ${PROJECT_NAME}_db_1:/$1.dump $CLI_HOME/db_dumps/$1.dump

    say "All done!"
}

function restore_db_backup() {
    [[ -z "$1" ]] && error "Dump name has to be provided as first parameter!" && exit 1

    say "First we need to clean up the scaffold!"
    scaffold_destroy
    up_scaffold

    say "Sleeping for 5 seconds for the database container to start up!"
    sleep 5

    say "Restoring dump from $CLI_HOME/db_dumps/$1.dump"
    docker cp $CLI_HOME/db_dumps/$1.dump ${PROJECT_NAME}_db_1:/backup.dump
    # docker exec -t ${PROJECT_NAME}_db_1 bash -c "PGPASSWORD=example dropdb -U postgres gitmesh-web && PGPASSWORD=example createdb -U postgres gitmesh-web"
    set +eo pipefail
    docker exec -t ${PROJECT_NAME}_db_1 bash -c "PGPASSWORD=example pg_restore --clean -U postgres -d gitmesh-web backup.dump && rm -f backup.dump"
    set -eo pipefail
    post_up_scaffold
    say "All done!"
}

function clean_orphans_silent() {
    # Clean orphans from scaffold silently
    $_DC --compatibility -p $PROJECT_NAME -f $CLI_HOME/scaffold.yaml down --remove-orphans >/dev/null 2>&1 || true
    
    # Clean orphans from premium scaffold if it exists
    if [ -f "$CLI_HOME/premium-scaffold.yaml" ]; then
        $_DC --compatibility -p $PROJECT_NAME -f $CLI_HOME/premium-scaffold.yaml down --remove-orphans >/dev/null 2>&1 || true
    fi
    
    # Clean orphans from all service files
    for SERVICE in $CONTAINERS
    do
        $_DC --compatibility -p $PROJECT_NAME -f "$CLI_HOME/services/${SERVICE}.yaml" down --remove-orphans >/dev/null 2>&1 || true
    done
    
    # Clean orphans from test environment
    $_DC -p "$PROJECT_NAME-test" -f $CLI_HOME/../backend/docker-compose.test.yaml down --remove-orphans >/dev/null 2>&1 || true
}

function clean_orphans() {
    say "Cleaning up orphan containers..."
    
    # Clean orphans from scaffold
    $_DC --compatibility -p $PROJECT_NAME -f $CLI_HOME/scaffold.yaml down --remove-orphans
    
    # Clean orphans from premium scaffold if it exists
    if [ -f "$CLI_HOME/premium-scaffold.yaml" ]; then
        $_DC --compatibility -p $PROJECT_NAME -f $CLI_HOME/premium-scaffold.yaml down --remove-orphans
    fi
    
    # Clean orphans from all service files
    for SERVICE in $CONTAINERS
    do
        say "Cleaning orphans for service $SERVICE..."
        $_DC --compatibility -p $PROJECT_NAME -f "$CLI_HOME/services/${SERVICE}.yaml" down --remove-orphans
    done
    
    # Clean orphans from test environment
    $_DC -p "$PROJECT_NAME-test" -f $CLI_HOME/../backend/docker-compose.test.yaml down --remove-orphans 2>/dev/null || true
    
    yell "Orphan cleanup completed!"
}

function scaffold() {
    HELP="${RESET}\nUsage:\n ./cli scaffold [ up | down | destroy | reset ]\n"

    [[ -z "$1" ]] && say "$HELP" && exit 1

    while test $# -gt 0
    do
        case "$1" in
            up) up_scaffold
                post_up_scaffold
                exit;
            ;;
            down) down_scaffold
                exit;
            ;;
            destroy) scaffold_destroy
                exit;
            ;;
            reset) scaffold_reset
                exit;
            ;;
            create-migration) create_migration $2
                exit;
            ;;
            migrate-up) migrate_local
                exit;
            ;;
            up-test)
                up_test_scaffold
                exit;
            ;;
            *) error "Invalid command '$1'" && say "$HELP"
                exit 1;
            ;;
        esac
        shift
    done
}

function service() {
    HELP="${RESET}\nUsage:\n ./cli service [ $HELP_STRING ]\n"
    [[ -z "$1" ]] && say "$HELP" && exit 1

    while test $# -gt 0
    do
    case "$1" in
            list)
                docker container ls | grep $LIST_STRING
                exit;
            ;;
            up-all) start_all_containers
                exit;
            ;;
            *) if [[ $CONTAINERS =~ (^|[[:space:]])"$1"($|[[:space:]]) ]] ; then
                    service_manipulator $1 $2 $3
                    exit;
                else
                    error "Invalid command '$1'" && say "$HELP"
                    exit 1;
                fi
            ;;
        esac
        shift
    done
}

function service_manipulator() {
    HELP="${RESET}\nUsage:\n ./cli service $1 [ up | down | restart | status | logs | id ]\n"

    [[ -z "$2" ]] && say "$HELP" && exit 1

    while test $# -gt 0
    do
        case "$2" in
            up) start_service "$1"
                exit;
            ;;
            down) kill_containers "$1"
                exit;
            ;;
            restart) kill_containers "$1" && start_service "$1"
                exit;
            ;;
            status) print_container_status "$1"
                exit;
            ;;
            logs) get_logs "$1"
                exit;
            ;;
            id) get_container_id "$1"
                exit;
            ;;
            *) error "Invalid command '$2'" && say "$HELP"
                exit 1;
            ;;
        esac
        shift
    done
}

function start_service() {
    export USER_ID=$(id -u)
    export GROUP_ID=$(id -g)

    if [[ ${DEV} ]]; then
        # Suppress orphan warnings by redirecting stderr, but keep the containers running
        $_DC --compatibility -p $PROJECT_NAME -f "$CLI_HOME/services/${1}.yaml" up --build -d ${1}-dev 2> >(grep -v "Found orphan containers" >&2)
    else
        $_DC --compatibility -p $PROJECT_NAME -f "$CLI_HOME/services/${1}.yaml" up --build -d ${1} 2> >(grep -v "Found orphan containers" >&2)
    fi
}

function kill_containers() {
    $_DC --compatibility -p $PROJECT_NAME -f "$CLI_HOME/services/${1}.yaml" rm -fs ${1} ${1}-dev
}

function get_logs() {
    if [[ ${DEV} ]]; then
        docker container logs -f $(get_container_id "$1-dev")
    else
        docker container logs -f $(get_container_id "$1")
    fi
}

function print_container_status() {
    CONTAINER_STATUS=$(check_container_status $1)

    if [[ ${CONTAINER_STATUS} ]]; then
        check_container_status "$1"
    else
        error "Down."
        exit 1;
    fi
}

function get_container_id() {
    docker container ls -a | grep "${PROJECT_NAME}_${1}_" | tr " " "\n" | head -n 1
}

function check_container_status() {
    docker container ls -a | grep "${PROJECT_NAME}_${1}_"
}

# <network-name> <subnet> <gateway>
function scaffold_set_up_network() {
    NETWORK_NAME="$1"
    NETWORK_SUBNET="$2"
    NETWORK_GATEWAY="$3"

    set +e pipefail
    NETWORK_ID=$(docker network ls | grep -F -e "$NETWORK_NAME " | tr " " "\n" | head -n 1)
    set -e pipefail

    if [[ ${NETWORK_ID} ]]; then
        say "The $NETWORK_NAME network is up and running."
    else
        docker network create -d bridge --subnet "$NETWORK_SUBNET" --gateway "$NETWORK_GATEWAY" "$NETWORK_NAME"
    fi
}

function migrate_local() {
    say "Building flyway migration image..."
    docker build --no-cache $DOCKER_PLATFORM_FLAGS -t gitmesh_flyway -f $CLI_HOME/../backend/src/database/Dockerfile.flyway $CLI_HOME/../backend/src/database --load
    say "Applying database migrations!"
    docker run --rm --network "${PROJECT_NAME}-bridge" \
        -e PGHOST=db \
        -e PGPORT=5432 \
        -e PGUSER=postgres \
        -e PGPASSWORD=example \
        -e PGDATABASE=gitmesh-web \
        gitmesh_flyway
}

function up_test_scaffold() {
    scaffold_set_up_network "${PROJECT_NAME}-bridge-test" $DOCKET_TEST_NETWORK_SUBNET $DOCKER_TEST_NETWORK_GATEWAY
    $_DC -p "$PROJECT_NAME-test" -f $CLI_HOME/../backend/docker-compose.test.yaml down --remove-orphans
    $_DC -p "$PROJECT_NAME-test" -f $CLI_HOME/../backend/docker-compose.test.yaml up -d --remove-orphans
    migrate_test
}

function migrate_test() {
    say "Building flyway migration image..."
    docker build -t gitmesh_flyway -f $CLI_HOME/../backend/src/database/Dockerfile.flyway $CLI_HOME/../backend/src/database

    say "Applying database migrations!"
    docker run --rm --network "${PROJECT_NAME}-bridge-test" \
        -e PGHOST=db-test \
        -e PGPORT=5432 \
        -e PGUSER=postgres \
        -e PGPASSWORD=example \
        -e PGDATABASE=gitmesh-web \
        gitmesh_flyway
}

function source_edition() {
    __EDITION=$(source $CLI_HOME/../backend/.env.dist.local && source $CLI_HOME/../backend/.env.override.local && echo $EDITION)
    nl
    say "Gitmesh edition detected: $__EDITION"
}

function check_init_premium() {
    source_edition
    if [ $__EDITION == "gitmesh-ee" ]; then
        $_DC --compatibility -p $PROJECT_NAME -f $CLI_HOME/premium-scaffold.yaml up -d --build
        init_unleash
    fi
}

function install_libs() {
    (cd $CLI_HOME/../services/scripts && ./install_lib_packages.sh)
}

function init_unleash() {
    install_libs
    set +e  # Don't exit on error
    (cd $CLI_HOME/../backend && source source-local.sh && pnpm i && pnpm run script:unleash-init)
    local unleash_exit_code=$?
    set -e  # Re-enable exit on error
    
    if [ $unleash_exit_code -ne 0 ]; then
        yell "Unleash initialization failed, but continuing with service startup..."
    else
        say "Unleash initialized successfully."
    fi
}

function up_scaffold() {
    scaffold_set_up_network "$PROJECT_NAME-bridge" $DOCKER_NETWORK_SUBNET $DOCKER_NETWORK_GATEWAY
    $_DC --compatibility -p $PROJECT_NAME -f $CLI_HOME/scaffold.yaml up -d --build --remove-orphans
}

function post_up_scaffold() {
    migrate_local
    bash $CLI_HOME/nango-integrations.sh
    check_init_premium
}

function down_scaffold() {
    $_DC --compatibility -p $PROJECT_NAME -f $CLI_HOME/scaffold.yaml down --remove-orphans
    if [ -f "$CLI_HOME/premium-scaffold.yaml" ]; then
            $_DC --compatibility -p $PROJECT_NAME -f $CLI_HOME/premium-scaffold.yaml down --remove-orphans
    fi
}

function scaffold_destroy() {
    say "\nWill delete all local state data (docker volumes) if you have any. Are you sure?"
    select reset_system_condition in "Yes" "No"; do
        case $reset_system_condition in
            'Yes' ) scaffold_destroy_confirmed; break;;
            'No' ) yell "Canceled!"; break;;
        esac
    done
}

function scaffold_reset() {
    scaffold_destroy
    up_scaffold
    post_up_scaffold
}

function kill_all_containers() {
    for i in $CONTAINERS
    do
        say "Killing service $i."

        if [[ $(check_container_status ${i}) ]]; then
            docker rm -f $(get_container_id ${i})
            yell "Service $i killed."
        elif [[ $(check_container_status ${i}-dev) ]]; then
            docker rm -f $(get_container_id ${i}-dev)
            yell "Service $i-dev killed."
        else
            error "Service $i not running."
        fi
        nl
    done
}

function scaffold_destroy_confirmed() {
    kill_all_containers
    $_DC --compatibility -p $PROJECT_NAME -f $CLI_HOME/scaffold.yaml down --remove-orphans
    if [ -f "$CLI_HOME/premium-scaffold.yaml" ]; then
            $_DC --compatibility -p $PROJECT_NAME -f $CLI_HOME/premium-scaffold.yaml down --remove-orphans
    fi

    # needed because if there are no volumes this might cause the script to exit
    set +eo pipefail
    VOLUMES=$(docker volume ls | tail -n +2 | tr -s " " | cut -d' ' -f2 | grep $PROJECT_NAME)
    set -eo pipefail
    if [[ ${VOLUMES} ]]; then
        _IFS=$IFS
        IFS=$' '
        NAMES=$VOLUMES
        IFS=$_IFS

        for name in $NAMES
        do
        say "Destroying volume $name!"
        docker volume rm -f $name
        done
    fi
}

function wait_for_db() {
    say "Waiting for scaffold to start!"
    sleep 3

    while [[ ! $(docker container ls | grep $PROJECT_NAME | grep db | grep Up) ]]; do
      sleep 1
    done

    say "Scaffold is up and running!"
}

# Health check functions
function check_service_health() {
    local service_name="$1"
    local check_command="$2"
    local timeout="${3:-5}"
    
    if timeout "$timeout" bash -c "$check_command" >/dev/null 2>&1; then
        echo "${GREEN}healthy${RESET}"
    else
        echo "${RED}unhealthy${RESET}"
    fi
}

function check_http_service_health() {
    local service_name="$1"
    local url="$2"
    local timeout="${3:-3}"
    
    # First check if container is running
    local container_status=$(check_container_health "${PROJECT_NAME}.*${service_name}")
    
    if [[ "$container_status" == *"not running"* ]]; then
        echo "${GREY}not running${RESET}"
        return 0
    fi
    
    if [[ "$container_status" == *"unhealthy"* ]]; then
        echo "${RED}unhealthy${RESET}"
        return 0
    fi
    
    # If container is running, try HTTP check
    if timeout "$timeout" curl -f -s "$url" >/dev/null 2>&1; then
        echo "${GREEN}healthy${RESET}"
    elif timeout "$timeout" curl -s "$url" >/dev/null 2>&1; then
        # HTTP connection works but might return non-200 status
        echo "${YELLOW}starting${RESET}"
    else
        # Container running but HTTP not responding
        echo "${YELLOW}starting${RESET}"
    fi
}

function check_container_health() {
    local container_pattern="$1"
    
    # Check if container exists (running or stopped)
    local container_id=$(docker ps -a --filter "name=$container_pattern" --format "{{.ID}}" 2>/dev/null | head -n1)
    
    if [[ -z "$container_id" ]]; then
        # No container exists at all
        echo "${GREY}not running${RESET}"
        return 0
    fi
    
    # Container exists, check if it's running
    local status=$(docker inspect --format='{{.State.Status}}' "$container_id" 2>/dev/null || echo "not_found")
    
    if [[ "$status" == "running" ]]; then
        # Check health status if available
        local health_status=$(docker inspect --format='{{.State.Health.Status}}' "$container_id" 2>/dev/null || echo "none")
        
        if [[ "$health_status" == "healthy" ]]; then
            echo "${GREEN}healthy${RESET}"
        elif [[ "$health_status" == "starting" ]]; then
            echo "${YELLOW}starting${RESET}"
        elif [[ "$health_status" == "unhealthy" ]]; then
            echo "${RED}unhealthy${RESET}"
        elif [[ "$health_status" == "none" ]]; then
            # No health check defined, but container is running - consider it healthy
            echo "${GREEN}healthy${RESET}"
        else
            echo "${RED}unhealthy${RESET}"
        fi
    else
        # Container exists but is not running (stopped, exited, etc.)
        echo "${RED}unhealthy${RESET}"
    fi
    return 0
}

function check_application_service_health() {
    local service_name="$1"
    
    # Check if container exists (running or stopped)
    local container_id=$(docker ps -a --filter "name=${PROJECT_NAME}_${service_name}_" --format "{{.ID}}" 2>/dev/null | head -n1)
    
    if [[ -z "$container_id" ]]; then
        # Try dev version
        container_id=$(docker ps -a --filter "name=${PROJECT_NAME}_${service_name}-dev_" --format "{{.ID}}" 2>/dev/null | head -n1)
    fi
    
    if [[ -z "$container_id" ]]; then
        # No container exists at all
        echo "${GREY}not running${RESET}"
        return 0
    fi
    
    # Container exists, check if it's running
    local status=$(docker inspect --format='{{.State.Status}}' "$container_id" 2>/dev/null || echo "not_found")
    
    if [[ "$status" == "running" ]]; then
        # Check health status if available
        local health_status=$(docker inspect --format='{{.State.Health.Status}}' "$container_id" 2>/dev/null || echo "none")
        
        if [[ "$health_status" == "healthy" ]]; then
            echo "${GREEN}healthy${RESET}"
        elif [[ "$health_status" == "starting" ]]; then
            echo "${YELLOW}starting${RESET}"
        elif [[ "$health_status" == "unhealthy" ]]; then
            echo "${RED}unhealthy${RESET}"
        elif [[ "$health_status" == "none" ]]; then
            # No health check defined, but container is running - consider it healthy
            echo "${GREEN}healthy${RESET}"
        else
            echo "${RED}unhealthy${RESET}"
        fi
    else
        # Container exists but is not running (stopped, exited, etc.)
        echo "${RED}unhealthy${RESET}"
    fi
    return 0
}

function should_check_service() {
    local service_name="$1"
    
    # Skip chat-orchestrator for CE edition
    if [[ "$__EDITION" != "gitmesh-ee" && "$service_name" == "chat-orchestrator" ]]; then
        return 1
    fi
    
    # Check if service is in ignored services array
    if [[ ${#INGORED_SERVICES[@]} -ne 0 ]]; then
        for IGNORED_SERVICE in "${INGORED_SERVICES[@]}"
        do
            if [[ "$service_name" == "${IGNORED_SERVICE}" ]]; then
                return 1
            fi
        done
    fi
    
    return 0
}

function print_success_and_ports() {
    # Temporarily disable exit on error for health checks
    set +e
    
    # Ensure __EDITION is set
    if [[ -z "$__EDITION" ]]; then
        source_edition
    fi
    
    echo -e "\n${YELLOW}Services and Ports:${RESET}"
    echo -e "--------------------------------------------------"
    
    local unhealthy_count=0
    local total_services=0
    
    # Core Application Services
    echo -e "${GREY}Core Services:${RESET}"
    
    # Check Frontend
    if should_check_service "frontend"; then
        local frontend_status=$(check_application_service_health "frontend")
        echo -e "${BLUE}Frontend:${RESET}             http://localhost:8081 - $frontend_status"
        [[ "$frontend_status" == *"unhealthy"* ]] && ((unhealthy_count++))
        [[ "$frontend_status" != *"not running"* ]] && ((total_services++))
    fi
    
    # Check Backend API
    if should_check_service "api"; then
        local backend_status=$(check_application_service_health "api")
        echo -e "${BLUE}Backend API:${RESET}          http://localhost:8080 - $backend_status"
        [[ "$backend_status" == *"unhealthy"* ]] && ((unhealthy_count++))
        [[ "$backend_status" != *"not running"* ]] && ((total_services++))
    fi
    
    # Check Search Sync API
    if should_check_service "search-sync-api"; then
        local search_sync_api_status=$(check_application_service_health "search-sync-api")
        echo -e "${BLUE}Search Sync API:${RESET}      http://localhost:8082 - $search_sync_api_status"
        [[ "$search_sync_api_status" == *"unhealthy"* ]] && ((unhealthy_count++))
        [[ "$search_sync_api_status" != *"not running"* ]] && ((total_services++))
    fi
    
    # Check Webhook API
    if should_check_service "webhook-api"; then
        local webhook_api_status=$(check_application_service_health "webhook-api")
        echo -e "${BLUE}Webhook API:${RESET}          http://localhost:8083 - $webhook_api_status"
        [[ "$webhook_api_status" == *"unhealthy"* ]] && ((unhealthy_count++))
        [[ "$webhook_api_status" != *"not running"* ]] && ((total_services++))
    fi
    
    # Check Chat Orchestrator (only for EE)
    if should_check_service "chat-orchestrator"; then
        local chat_status=$(check_application_service_health "chat-orchestrator")
        echo -e "${BLUE}Chat Orchestrator:${RESET}    http://localhost:8001 - $chat_status"
        [[ "$chat_status" == *"unhealthy"* ]] && ((unhealthy_count++))
        [[ "$chat_status" != *"not running"* ]] && ((total_services++))
    fi
    
    # echo ""
    # echo -e "${GREY}Worker Services:${RESET}"
    
    # # Check all worker services
    # if should_check_service "automations-worker"; then
    #     local automations_worker_status=$(check_application_service_health "automations-worker")
    #     echo -e "${BLUE}Automations Worker:${RESET}   - $automations_worker_status"
    #     [[ "$automations_worker_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    #     [[ "$automations_worker_status" != *"not running"* ]] && ((total_services++))
    # fi
    
    # if should_check_service "data-sink-worker"; then
    #     local data_sink_worker_status=$(check_application_service_health "data-sink-worker")
    #     echo -e "${BLUE}Data Sink Worker:${RESET}     - $data_sink_worker_status"
    #     [[ "$data_sink_worker_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    #     [[ "$data_sink_worker_status" != *"not running"* ]] && ((total_services++))
    # fi
    
    # if should_check_service "emails-worker"; then
    #     local emails_worker_status=$(check_application_service_health "emails-worker")
    #     echo -e "${BLUE}Emails Worker:${RESET}        - $emails_worker_status"
    #     [[ "$emails_worker_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    #     [[ "$emails_worker_status" != *"not running"* ]] && ((total_services++))
    # fi
    
    # if should_check_service "integration-data-worker"; then
    #     local integration_data_worker_status=$(check_application_service_health "integration-data-worker")
    #     echo -e "${BLUE}Integration Data Worker:${RESET} - $integration_data_worker_status"
    #     [[ "$integration_data_worker_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    #     [[ "$integration_data_worker_status" != *"not running"* ]] && ((total_services++))
    # fi
    
    # if should_check_service "integration-run-worker"; then
    #     local integration_run_worker_status=$(check_application_service_health "integration-run-worker")
    #     echo -e "${BLUE}Integration Run Worker:${RESET} - $integration_run_worker_status"
    #     [[ "$integration_run_worker_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    #     [[ "$integration_run_worker_status" != *"not running"* ]] && ((total_services++))
    # fi
    
    # if should_check_service "integration-stream-worker"; then
    #     local integration_stream_worker_status=$(check_application_service_health "integration-stream-worker")
    #     echo -e "${BLUE}Integration Stream Worker:${RESET} - $integration_stream_worker_status"
    #     [[ "$integration_stream_worker_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    #     [[ "$integration_stream_worker_status" != *"not running"* ]] && ((total_services++))
    # fi
    
    # if should_check_service "integration-sync-worker"; then
    #     local integration_sync_worker_status=$(check_application_service_health "integration-sync-worker")
    #     echo -e "${BLUE}Integration Sync Worker:${RESET} - $integration_sync_worker_status"
    #     [[ "$integration_sync_worker_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    #     [[ "$integration_sync_worker_status" != *"not running"* ]] && ((total_services++))
    # fi
    
    # if should_check_service "search-sync-worker"; then
    #     local search_sync_worker_status=$(check_application_service_health "search-sync-worker")
    #     echo -e "${BLUE}Search Sync Worker:${RESET}   - $search_sync_worker_status"
    #     [[ "$search_sync_worker_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    #     [[ "$search_sync_worker_status" != *"not running"* ]] && ((total_services++))
    # fi
    
    # if should_check_service "nodejs-worker"; then
    #     local nodejs_worker_status=$(check_application_service_health "nodejs-worker")
    #     echo -e "${BLUE}NodeJS Worker:${RESET}        - $nodejs_worker_status"
    #     [[ "$nodejs_worker_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    #     [[ "$nodejs_worker_status" != *"not running"* ]] && ((total_services++))
    # fi
    
    # if should_check_service "python-worker"; then
    #     local python_worker_status=$(check_application_service_health "python-worker")
    #     echo -e "${BLUE}Python Worker:${RESET}        - $python_worker_status"
    #     [[ "$python_worker_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    #     [[ "$python_worker_status" != *"not running"* ]] && ((total_services++))
    # fi
    
    # if should_check_service "job-generator"; then
    #     local job_generator_status=$(check_application_service_health "job-generator")
    #     echo -e "${BLUE}Job Generator:${RESET}        - $job_generator_status"
    #     [[ "$job_generator_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    #     [[ "$job_generator_status" != *"not running"* ]] && ((total_services++))
    # fi
    
    # if should_check_service "discord-ws"; then
    #     local discord_ws_status=$(check_application_service_health "discord-ws")
    #     echo -e "${BLUE}Discord WebSocket:${RESET}    - $discord_ws_status"
    #     [[ "$discord_ws_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    #     [[ "$discord_ws_status" != *"not running"* ]] && ((total_services++))
    # fi
    
    echo ""
    echo -e "${GREY}Infrastructure Services:${RESET}"
    
    # Infrastructure services are always checked
    # Check Nango - has HTTP health endpoint
    local nango_status=$(check_http_service_health "nango" "http://localhost:3003/health")
    echo -e "${BLUE}Nango:${RESET}                http://localhost:3003 - $nango_status"
    [[ "$nango_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    [[ "$nango_status" != *"not running"* ]] && ((total_services++))
    
    # Check CubeJS - has HTTP endpoint
    local cubejs_status=$(check_http_service_health "cubejs" "http://localhost:4000/readyz")
    echo -e "${BLUE}CubeJS:${RESET}               http://localhost:4000 - $cubejs_status"
    [[ "$cubejs_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    [[ "$cubejs_status" != *"not running"* ]] && ((total_services++))
    
    # Check PostgreSQL - has built-in health check
    local postgres_status=$(check_container_health "${PROJECT_NAME}.*db")
    echo -e "${BLUE}PostgreSQL:${RESET}           http://localhost:5432 - $postgres_status"
    [[ "$postgres_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    [[ "$postgres_status" != *"not running"* ]] && ((total_services++))
    
    # Check Redis - has built-in health check
    local redis_status=$(check_container_health "${PROJECT_NAME}.*redis")
    echo -e "${BLUE}Redis:${RESET}                http://localhost:6379 - $redis_status"
    [[ "$redis_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    [[ "$redis_status" != *"not running"* ]] && ((total_services++))
    
    # Check Temporal UI - has HTTP endpoint
    local temporal_status=$(check_http_service_health "temporal" "http://localhost:8233")
    echo -e "${BLUE}Temporal UI:${RESET}          http://localhost:8233 - $temporal_status"
    [[ "$temporal_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    [[ "$temporal_status" != *"not running"* ]] && ((total_services++))
    
    # Check Kafka - has built-in health check
    local kafka_status=$(check_container_health "${PROJECT_NAME}.*kafka")
    echo -e "${BLUE}Kafka:${RESET}                http://localhost:9094 - $kafka_status"
    [[ "$kafka_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    [[ "$kafka_status" != *"not running"* ]] && ((total_services++))
    
    # Check OpenSearch - has HTTP health endpoint
    local opensearch_status=$(check_http_service_health "open-search" "http://localhost:9200/_cluster/health")
    echo -e "${BLUE}OpenSearch:${RESET}           http://localhost:9200 - $opensearch_status"
    [[ "$opensearch_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    [[ "$opensearch_status" != *"not running"* ]] && ((total_services++))
    
    # Check SQS UI - has HTTP endpoint
    local sqs_status=$(check_http_service_health "sqs" "http://localhost:9325")
    echo -e "${BLUE}SQS UI:${RESET}               http://localhost:9325 - $sqs_status"
    [[ "$sqs_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    [[ "$sqs_status" != *"not running"* ]] && ((total_services++))
    
    # Check Ollama - has HTTP endpoint
    local ollama_status=$(check_http_service_health "ollama" "http://localhost:11434")
    echo -e "${BLUE}Ollama:${RESET}               http://localhost:11434 - $ollama_status"
    [[ "$ollama_status" == *"unhealthy"* ]] && ((unhealthy_count++))
    [[ "$ollama_status" != *"not running"* ]] && ((total_services++))
    
    # Check Unleash (only for EE) - has HTTP endpoint
    if [[ "$__EDITION" == "gitmesh-ee" ]]; then
        local unleash_status=$(check_http_service_health "unleash[^-]" "http://localhost:4242/health")
        echo -e "${BLUE}Unleash:${RESET}              http://localhost:4242 - $unleash_status"
        [[ "$unleash_status" == *"unhealthy"* ]] && ((unhealthy_count++))
        [[ "$unleash_status" != *"not running"* ]] && ((total_services++))
    fi
    
    echo -e "--------------------------------------------------"
    
    # Print summary message
    if [[ $unhealthy_count -eq 0 ]]; then
        echo -e "\n${GREEN}Script ran successfully! All $total_services services are healthy.${RESET}"
    else
        local healthy_count=$((total_services - unhealthy_count))
        echo -e "\n${YELLOW}Script ran successfully but $unhealthy_count of $total_services service(s) are unhealthy.${RESET}"
        echo -e "${GREEN}$healthy_count services are healthy.${RESET}"
        echo -e "${GREY}Check the logs for unhealthy services: ./cli service <service-name> logs${RESET}"
    fi
    
    # Re-enable exit on error
    set -e
}

function start() {
    if [[ -z "$CLEAN_START" ]]; then
        up_scaffold
        post_up_scaffold
    else
        scaffold_reset
    fi

    for SERVICE in $CONTAINERS
    do
        if [[ "$__EDITION" != "gitmesh-ee" ]]; then
             if [[ "$SERVICE" == "chat-orchestrator" ]]; then
                SKIP=1
             fi
        fi

        if [[ ${#INGORED_SERVICES[@]} -ne 0 ]]; then
            for IGNORED_SERVICE in "${INGORED_SERVICES[@]}"
            do
                if [[ "$SERVICE" == "${IGNORED_SERVICE}" ]]; then
                    SKIP=1
                    break
                fi
            done
        fi

        if [[ -z "$SKIP" ]]; then
            say "Starting service $SERVICE."
            start_service $SERVICE
            nl
        fi
        unset SKIP
    done

    print_success_and_ports
}

SCRIPT_USAGE="${YELLOW}${PROJECT_NAME} CLI ${RESET}\n\nExample usage: ./cli [ prod, dev, clean-dev, prod-ee, dev-ee, clean-dev-ee, prod-backend, dev-backend, clean-dev-backend, clean-orphans, scaffold =>, service =>, build =>, build-and-push ]"

[[ -z "$1" ]] && say "$SCRIPT_USAGE" && exit 1
while test $# -gt 0
do
    case "$1" in
        clean-orphans)
            clean_orphans
            exit;
        ;;
        scaffold) scaffold $2 $3 $4 $5
            echo -e "\nScript ran successfully. Check the website on http://localhost:8081";
            exit;
        ;;
        service)
            service $2 $3 $4 $5
            exit;
        ;;
        services)
            service $2 $3 $4 $5
            exit;
        ;;
        prod)
            start
            exit;
        ;;
        start-e2e)
            declare -a INGORED_SERVICES=("python-worker" "job-generator" "discord-ws" "data-sink-worker" "integration-data-worker" "integration-run-worker" "integration-stream-worker")
            start
            exit;
        ;;
        start-be)
            declare -a INGORED_SERVICES=("python-worker" "frontend" "discord-ws")
            start
            exit;
        ;;
        dev)
            sed -i 's/VUE_APP_EDITION=gitmesh-ee/VUE_APP_EDITION=gitmesh-ce/g' $CLI_HOME/../frontend/.env.override.local
            if grep -q "EDITION=" $CLI_HOME/../backend/.env.override.local; then
                    sed -i 's/EDITION=.*/EDITION=gitmesh-ce/g' $CLI_HOME/../backend/.env.override.local
                else
                    echo "EDITION=gitmesh-ce" >> $CLI_HOME/../backend/.env.override.local
            fi
            DEV=1
            start
            exit;
        ;;
        clean-dev)
            # Clean up cache files and old compiled JS to prevent stale code issues
            bash $CLI_HOME/cleanup-cache.sh
            
            if [[ "$2" == "--ee" ]]; then
                if grep -q "VUE_APP_EDITION=" $CLI_HOME/../frontend/.env.override.local; then
                    sed -i 's/VUE_APP_EDITION=.*/VUE_APP_EDITION=gitmesh-ee/g' $CLI_HOME/../frontend/.env.override.local
                else
                    echo "VUE_APP_EDITION=gitmesh-ee" >> $CLI_HOME/../frontend/.env.override.local
                fi

                if grep -q "EDITION=" $CLI_HOME/../backend/.env.override.local; then
                    sed -i 's/EDITION=.*/EDITION=gitmesh-ee/g' $CLI_HOME/../backend/.env.override.local
                else
                    echo "EDITION=gitmesh-ee" >> $CLI_HOME/../backend/.env.override.local
                fi
                shift
            else
                if grep -q "VUE_APP_EDITION=" $CLI_HOME/../frontend/.env.override.local; then
                    sed -i 's/VUE_APP_EDITION=.*/VUE_APP_EDITION=gitmesh-ce/g' $CLI_HOME/../frontend/.env.override.local
                else
                    echo "VUE_APP_EDITION=gitmesh-ce" >> $CLI_HOME/../frontend/.env.override.local
                fi

                if grep -q "EDITION=" $CLI_HOME/../backend/.env.override.local; then
                    sed -i 's/EDITION=.*/EDITION=gitmesh-ce/g' $CLI_HOME/../backend/.env.override.local
                else
                    echo "EDITION=gitmesh-ce" >> $CLI_HOME/../backend/.env.override.local
                fi
            fi
            CLEAN_START=1
            DEV=1
            start
            exit;
        ;;
        prod-backend)
            declare -a INGORED_SERVICES=("frontend")
            start
            exit;
        ;;
        dev-backend)
            declare -a INGORED_SERVICES=("frontend")
            DEV=1
            start
            exit;
        ;;
        clean-dev-backend)
            # Clean up cache files and old compiled JS to prevent stale code issues
            bash $CLI_HOME/cleanup-cache.sh
            
            declare -a INGORED_SERVICES=("frontend")
            CLEAN_START=1
            DEV=1
            start
            exit;
        ;;
        prod-ee)
            sed -i 's/VUE_APP_EDITION=gitmesh-ce/VUE_APP_EDITION=gitmesh-ee/g' $CLI_HOME/../frontend/.env.override.local
            start
            exit;
        ;;
        dev-ee)
            # Check for premium directories before starting EE mode
            if ! node $CLI_HOME/check-premium-dirs.js > /dev/null 2>&1; then
                error "Premium directories not found or incomplete. Cannot start Enterprise Edition."
                say "Missing premium directories. Falling back to Community Edition..."
                say "Use './cli dev' for Community Edition development."
                exit 1
            fi
            
            say "Premium directories found - starting Enterprise Edition..."
            sed -i 's/VUE_APP_EDITION=gitmesh-ce/VUE_APP_EDITION=gitmesh-ee/g' $CLI_HOME/../frontend/.env.override.local
            if grep -q "EDITION=" $CLI_HOME/../backend/.env.override.local; then
                    sed -i 's/EDITION=.*/EDITION=gitmesh-ee/g' $CLI_HOME/../backend/.env.override.local
                else
                    echo "EDITION=gitmesh-ee" >> $CLI_HOME/../backend/.env.override.local
            fi
            DEV=1
            start
            exit;
        ;;
        clean-dev-ee)
            # Check for premium directories before starting EE mode
            if ! node $CLI_HOME/check-premium-dirs.js > /dev/null 2>&1; then
                error "Premium directories not found or incomplete. Cannot start Enterprise Edition."
                say "Missing premium directories. Falling back to Community Edition..."
                say "Use './cli clean-dev' for Community Edition development."
                exit 1
            fi
            
            say "Premium directories found - starting Enterprise Edition..."
            
            # Clean up cache files to prevent ENOENT errors
            bash $CLI_HOME/cleanup-cache.sh
            
            sed -i 's/VUE_APP_EDITION=gitmesh-ce/VUE_APP_EDITION=gitmesh-ee/g' $CLI_HOME/../frontend/.env.override.local
            if grep -q "EDITION=" $CLI_HOME/../backend/.env.override.local; then
                    sed -i 's/EDITION=.*/EDITION=gitmesh-ee/g' $CLI_HOME/../backend/.env.override.local
                else
                    echo "EDITION=gitmesh-ee" >> $CLI_HOME/../backend/.env.override.local
            fi
            CLEAN_START=1
            DEV=1
            start
            exit;
        ;;
        build)
            build $2 $3
            exit;
        ;;
        build-and-push)
            PUSH=1
            build $2 $3
            exit;
        ;;
        db-backup)
            db_backup $2
            exit;
        ;;
        db-restore)
            restore_db_backup $2
            exit;
        ;;
        *) error "Invalid command '$1'" && say "$SCRIPT_USAGE"
            exit 1;
        ;;
    esac
    shift
done
